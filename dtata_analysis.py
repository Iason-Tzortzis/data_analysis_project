# -*- coding: utf-8 -*-
"""Copy of Copy of Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ElJOZNeDPB4pV11MDBrdPyuswxz8xqbE

Importing all the necessary libraries
"""

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.linear_model import LinearRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn import svm
from scipy.stats import randint
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

"""Reading the data and creating the columns of the dataset"""

columns = ['class label','lepton pT','lepton eta','lepton phi','missing energy magnitude','missing energy phi','jet 1 pt',' jet 1 eta','jet 1 phi',' jet 1 b-tag','jet 2 pt','jet 2 eta','jet 2 phi','jet 2 b-tag','jet 3 pt',
         'jet 3 eta','jet 3 phi','jet 3 b-tag','jet 4 pt','jet 4 eta','jet 4 phi','jet 4 b-tag','m_jj','m_jjj',
         'm_lv','m_jlv','m_bb','m_wbb','m_wwbb']
path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz'
data = pd.read_csv(path, compression='gzip', names=columns)
data.info()

"""Creating the training dataset that were gonna use"""

train_set, test_set = train_test_split(data, test_size=.999, random_state=20)
labels = train_set['class label'].copy()
predictors = train_set.drop('class label', axis=1)
predictors.head()

"""Getting information about the training dataset that we created"""

predictors.info()

"""Using the support vector machine learning model on the training dataset"""

SVM = svm.SVC()
SVM.fit(predictors,labels)
pred1 = SVM.predict(predictors)
AM1 = accuracy_score(labels,pred1)
F1 = f1_score(labels,pred1, average='micro')

"""Using the K-nearest neighbors (KNN)  learning algorithm on the training dataset"""

kneighbors = KNeighborsClassifier(n_neighbors=5)
kneighbors.fit(predictors,labels)
pred2 = kneighbors.predict(predictors)
AM2 = accuracy_score(labels,pred2)
F2 = f1_score(labels,pred2, average='micro')

"""Using the tree classifier on the training dataset"""

tree_reg = DecisionTreeClassifier()
tree_reg.fit(predictors,labels)

pred3 = tree_reg.predict(predictors)
AM3 = accuracy_score(labels,pred3)
F3 = f1_score(labels,pred3, average='micro')
pred2 = tree_reg.predict(predictors)



scoresA = cross_val_score(tree_reg,predictors,labels,scoring='accuracy',cv=4)
scoresF = cross_val_score(tree_reg,predictors,labels,scoring='f1_micro',cv=4)
min11 = scoresA[0]
min12 = scoresF[0] 
for i in range(1,len(scoresA)): 
    if scoresA[i]<min1A: 
        min11=scoresA[i] 
    
for i in range(1,len(scoresF)): 
    if scoresF[i]<min1F: 
        min12=scoresF[i]

"""Using the random forest classifier on the training dataset"""

forest = RandomForestClassifier(n_estimators=100, random_state=40)
forest.fit(predictors,labels)


forest_scoresA = cross_val_score(forest,predictors,labels,scoring='accuracy', cv=4)
forest_scoresF = cross_val_score(forest,predictors,labels,scoring='f1_micro', cv=4)
min21 = forest_scoresA[0]
min22 = forest_scoresF[0]
for i in range(1,len(forest_scoresA)): 
    if forest_scoresA[i]<min21: 
        min21=forest_scoresA[i] 

for i in range(1,len(forest_scoresF)): 
    if forest_scoresF[i]<min22: 
        min22=forest_scoresF[i]

"""Model fitting the training dataset"""

param_grid = [
              {'n_estimators': [5,15,30], 'max_features': [2,4,6,8]},
              {'bootstrap': [False], 'n_estimators':[5,15], 'max_features':[2,4,6,8]}
]

forestF = RandomForestClassifier(random_state=40)

grid_search = GridSearchCV(forestF,param_grid,cv=4,scoring='accuracy',return_train_score=True)
grid_search.fit(predictors,labels)
cvres = grid_search.cv_results_

param_distribs = {
    'n_estimators': randint(low=1,high=200),
    'max_features': randint(low=1,high=8)
}

rnd_search = RandomizedSearchCV(forestF, param_distributions=param_distribs,n_iter=10,cv=4,scoring='accuracy',random_state=40)
rnd_search.fit(predictors,labels)

cvres1 = rnd_search.cv_results_

"""Selecting the best model based on accuracy and the F1 Score"""

final_tree_model = rnd_search.best_estimator_


final_tree_predictions = final_tree_model.predict(predictors)

final_scoresA = cross_val_score(forestF,predictors,labels,scoring='accuracy', cv=4)
final_scoresF = cross_val_score(forestF,predictors,labels,scoring='f1_micro', cv=4)
test_predictors = test_set.drop('class label', axis=1)

test_labels = test_set['class label'].copy()
final_tree_predictions = final_tree_model.predict(test_predictors)
min31 = final_scoresA[0]
min32 = final_scoresF[0]
for i in range(1,len(final_scoresA)): 
    if final_scoresA[i]<min31: 
        min31=final_scoresA[i] 

for i in range(1,len(final_scoresF)): 
    if final_scoresF[i]<min32: 
        min32=final_scoresF[i]

"""DATA OF THE DIAGRAMS

ACCURACY DATA

AC1 = support vectors machines accuracy
AC2 = K nearest neighbor learning algorithm accuracy
AC3 = decision tree  no cross validation accuracy
AC4 = decision tree cross validation best accuracy
AC5 = random forest classifier best accuracy
AC6 = random forest classifier best Model and best accuracy
"""

AC1 = AM1 
AC2 = AM2
AC3 = AM3 
AC4 = min11
AC5 = min21
AC6 = min31

"""F1 SCORES DATA

F1S = support vector machines F1 score
F1K = K-nearest neighbors learning algorithm F1 score
F1DEC = decision tree - F1 score
F1DEC-C = decision tree -cross validation F1 score
F1RF = random forest best F1 score
F1RF-C =  random forest classifier best model and best F1 score
"""

F1S = F1 
F1K = F2 
F1DEC = F3 
F1DEC-C = min12 
F1RF = min22 
F1RF-C = min32

"""Putting data inside tables"""

AD = [AC1,AC2,AC3,AC4,AC5,AC6]
F1D = [F1S,F1K,F1DEC,F1DEC-C,F1RF,F1RF-C]

"""Plotting the graphs of the Accuracy of the models and their F1 score and giving them titles and labels"""

plt.grid(True)
plt.title("Acurracy Scores of the models we used")
plt.xlabel("Numbers of each model")
plt.ylabel("Accuracy Score")
plt.style.use('seaborn-bright')
plt.plot([AC1,AC2,AC3,AC4,AC5,AC6],'bo--')
plt.savefig('sample_data/Accuracy_Score.png', format='png')
plt.show()

plt.grid(True)
plt.title("F1 Scores of the models we used")
plt.xlabel("Numbers of each model")
plt.ylabel("F1 Score")
plt.plot([F1S,F1K,F1DEC,F1DEC-C,F1RF,F1RF-C], 'ro--')
plt.savefig('sample_data/F1_Score.png', format='png')
plt.show()

"""Printing the success message and saving the graphs in the sample_data folder"""

print("The graphs of Accuracy_Score.png and F1_Score.png have been saved in folder sample_data")